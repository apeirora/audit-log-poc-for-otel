version: "3"

description: Taskfile for port-forwarding the otel-demo frontend-proxy service.

vars:
  WORK_DIR: "{{ .ROOT_DIR }}/work_dir"
  CLUSTER:
    sh: |
      if {{ .KUBECTL_CMD }} cluster-info >/dev/null 2>&1; then
        echo true
      else
        echo false
      fi
  NODE_IP:
    sh: |
      {{ if eq .CLUSTER "true" }} {{ .KUBECTL_CMD }} get nodes -o yaml | yq '.items[] | select(.metadata.name | test("otel-audit-log")) | .metadata.annotations."alpha.kubernetes.io/provided-node-ip"' {{ end }}
  COLLECTOR_HTTP:
    sh: |
      {{ if eq .CLUSTER "true" }} {{ .KUBECTL_CMD }} --namespace otel-demo --output yaml get svc otel-collector | yq '.spec.ports[] | select(.name == "otlp-http") | .nodePort' {{ end }}
  COLLECTOR_GRPC:
    sh: |
      {{ if eq .CLUSTER "true" }} {{ .KUBECTL_CMD }} --namespace otel-demo --output yaml get svc otel-collector | yq '.spec.ports[] | select(.name == "otlp") | .nodePort' {{ end }}

includes:
  tools:
    desc: Install required tools (k3d, kubectl, kind).
    taskfile: ./tools.yaml
    internal: true
  istio:
    desc: Install and manage Istio in the local cluster.
    taskfile: ./istio.yaml
    internal: true

tasks:
  install:
    desc: Install otel-demo in the local cluster.
    run: once
    deps:
      - task: tools:install-helm
      - task: istio:install
    requires:
      vars: [HELM_CMD]
    preconditions:
      - sh: "{{ .KUBECTL_CMD }} cluster-info >/dev/null 2>&1"
        msg: "Please ensure that you have a k8s-cluster running. Try:\ttask cluster:start"
    status:
      - "{{ .HELM_CMD }} list --namespace otel-demo -o json | jq -r '.[].status' | grep -q deployed"
    cmds:
      - "{{ .HELM_CMD }} repo add open-telemetry https://open-telemetry.github.io/opentelemetry-helm-charts >/dev/null 2>&1"
      - "{{ .HELM_CMD }} install --values helm/otel-demo-overrides.yaml my-otel-demo open-telemetry/opentelemetry-demo --namespace otel-demo --create-namespace"
      - "{{ .KUBECTL_CMD }} apply -f kubectl/istio-otelcol-fault-injection.yaml"
      - "{{ .KUBECTL_CMD }} apply -f kubectl/istio-permissive-mtls.yaml"

  upgrade:
    desc: Upgrade otel-demo in the local cluster.
    run: once
    deps:
      - task: tools:install-helm
    requires:
      vars: [HELM_CMD]
    cmds:
      - "{{ .HELM_CMD }} upgrade --install --values helm/otel-demo-overrides.yaml my-otel-demo open-telemetry/opentelemetry-demo --namespace otel-demo --create-namespace"
      - "{{ .KUBECTL_CMD }} apply -f kubectl/istio-otelcol-fault-injection.yaml"
      - "{{ .KUBECTL_CMD }} apply -f kubectl/istio-permissive-mtls.yaml"

  status:
    desc: Check the status of otel-demo in the local cluster.
    deps:
      - task: install
    requires:
      vars: [HELM_CMD]
    cmds:
      - "{{ .HELM_CMD }} status --namespace otel-demo my-otel-demo"

  delete:
    desc: Delete otel-demo from the local cluster.
    deps:
      - task: tools:install-helm
    requires:
      vars: [HELM_CMD]
    status:
      - "! {{ .HELM_CMD }} list --namespace otel-demo | grep -q my-otel-demo"
    cmds:
      - "{{ .HELM_CMD }} uninstall my-otel-demo --namespace otel-demo --ignore-not-found"
      - "{{ .KUBECTL_CMD }} delete -f kubectl/istio-otelcol-fault-injection.yaml"
      - "{{ .KUBECTL_CMD }} delete -f kubectl/istio-permissive-mtls.yaml"

  port-forward:
    desc: Port-forward the otel-demo frontend-proxy service to localhost:8080.
    deps:
      - task: install
      - task: tools:install-kubectl
    requires:
      vars: [KUBECTL_CMD]
    preconditions:
      - sh: "{{ .KUBECTL_CMD }} get svc/frontend-proxy --namespace otel-demo >/dev/null 2>&1"
      - sh: "{{ .KUBECTL_CMD }} get pods --namespace otel-demo --field-selector=status.phase=Running | grep -q frontend-proxy"
        msg: "Please wait for the frontend-proxy pod to be in Running state."
    cmds:
      - "{{ .KUBECTL_CMD }} --namespace otel-demo port-forward svc/frontend-proxy 8080:8080"

  tweak-config:
    desc: Tweak the otel-collector configuration in the otel-demo namespace.
    deps:
      - task: create-work-dir
      - task: install
      - task: tools:install-kubectl
    requires:
      vars: [KUBECTL_CMD]
    cmds:
      - "{{ .KUBECTL_CMD }} --namespace otel-demo --output yaml get configmap otel-collector > {{ .WORK_DIR }}/otel-collector-configmap.yaml"
      - "{{ .KUBECTL_CMD }} --namespace otel-demo --output yaml get service otel-collector > {{ .WORK_DIR }}/otel-collector-service.yaml"
      - yq eval '.data.relay = load_str("{{ .ROOT_DIR }}/otel-collector/config.yaml")' {{ .WORK_DIR }}/otel-collector-configmap.yaml > {{ .WORK_DIR }}/otel-collector-configmap-new.yaml
      - yq eval '.spec.ports |= map(select(.name == "otlp" or .name == "otlp-http"))' {{ .WORK_DIR }}/otel-collector-service.yaml > {{ .WORK_DIR }}/otel-collector-service-new.yaml
      - "{{ .KUBECTL_CMD }} --namespace otel-demo apply --filename {{ .WORK_DIR }}/otel-collector-configmap-new.yaml"
      - "{{ .KUBECTL_CMD }} --namespace otel-demo apply --filename {{ .WORK_DIR }}/otel-collector-service-new.yaml"
      - "{{ .KUBECTL_CMD }} --namespace otel-demo rollout restart deployment otel-collector"

  create-work-dir:
    desc: Create the work directory ({{ .WORK_DIR }}) if it doesn't exist.
    internal: true
    run: once
    platforms: [linux, darwin]
    requires:
      vars: [WORK_DIR]
    status:
      - test -d "{{ .WORK_DIR }}"
    cmds:
      - mkdir -p "{{ .WORK_DIR }}"

  busybox:
    desc: Run a busybox container in the otel-demo namespace.
    deps:
      - task: tools:install-kubectl
    requires:
      vars: [KUBECTL_CMD]
    cmds:
      - "{{ .KUBECTL_CMD }} run run -it --rm --restart=Never --namespace otel-demo --image=busybox -- sh"

  alpine-sidecar:
    desc: Run a
    deps:
      - task: tools:install-kubectl
    requires:
      vars: [KUBECTL_CMD]
    cmds:
      - "{{ .KUBECTL_CMD }} exec -it $({{ .KUBECTL_CMD }} get pods --namespace otel-demo --field-selector=status.phase=Running -o name | grep otel-collector) -c alpine-sidecar --namespace otel-demo -- /bin/sh"

  export-collector:
    desc: Shows the otel-collector service details (IP address and ports).
    requires:
      vars: [NODE_IP, COLLECTOR_GRPC, COLLECTOR_HTTP]
    cmds:
      - |
        echo export OTEL_EXPORTER_OTLP_ENDPOINT="http://{{ .NODE_IP }}" && \
        echo export OTEL_EXPORTER_OTLP_ENDPOINT_GRPC="http://{{ .NODE_IP }}:{{ .COLLECTOR_GRPC }}" && \
        echo export OTEL_EXPORTER_OTLP_ENDPOINT_HTTP="http://{{ .NODE_IP }}:{{ .COLLECTOR_HTTP }}"
